1、决策树：
	信息论
	熵
	计算公式
	评价标准：信息增益
	gini系数：评价系统纯，越纯越小

2、决策树，绘制图形
	sklearn决策树基于Cart，二分类-------->都是二叉树
	graphviz画图方式，查看决策树原理图

3、决策树，基本实际中不用
	集成树
	集成算法


4、集成算法：
	随机森林：由多颗决策树组成，数据集随机抽取
	极端随机森林：多颗决策树组成，数据集随机抽取，更近了一步：选择属性列分时，随机方式

5、套袋法：
	上午所学的：随机森立和极端随机森林
	给多颗树，每棵树，相似的，数据不同
	每棵树，就像袋子

	在集合算法中，装袋方法形成一类算法，其在原始训练集的随机子集上构建黑盒（封装）估计器的若干实例（多颗树），然后聚合它们的各个预测以形成最终预测



6、Adaboost多颗树组成的
	boost提升，算法中提升了什么
	增强算法
	一个数据之所以没有区分开，是因为特征不足够明显
	数据采集回来，数据放大，系数变大，‘放大镜’在看样本


7、gbdt：
	梯度提升树
	残差学习，改进结果

8、Xgboost：
	陈天奇，开发
	Xgboost是对gbdt升级
	几十个博士维护升级修改这些代码
	一般情况下，Xgboost效果好于Gbdt


9、LGBM ----->ligthgbm:
	微软技术很厉害
	light：
		算法轻量级
		点亮算







